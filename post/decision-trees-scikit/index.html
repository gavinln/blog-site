	<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en-us" lang="en-us">
<head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="generator" content="Hugo 0.15" />

  
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title> Decision trees on the Iris data set &middot; Human Learning Machine Learning </title>

  
  <link rel="stylesheet" href="http://gavinln.github.io/blog-site/css/poole.css">
  <link rel="stylesheet" href="http://gavinln.github.io/blog-site/css/syntax.css">
  <link rel="stylesheet" href="http://gavinln.github.io/blog-site/css/hyde.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">

  
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="http://gavinln.github.io/blog-site/apple-touch-icon-144-precomposed.png">
  <link rel="shortcut icon" href="http://gavinln.github.io/blog-site/favicon.png">

  
  <link href="" rel="alternate" type="application/rss+xml" title="Human Learning Machine Learning" />
</head>

	<body class="theme-base-0b">
		<div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <a href="http://gavinln.github.io/blog-site/"><h1>Human Learning Machine Learning</h1></a>
      <p class="lead">
	Posts about Machine learning.
      </p>
    </div>

    <ul class="sidebar-nav">
      <li><a href="http://gavinln.github.io/blog-site/">Home</a> </li>
      
        <li><a href="http://gavinln.github.io/blog-site/post/accuracy-precision-recall/"> Accuracy, precision, recall for machine learning </a></li>
      
        <li><a href="http://gavinln.github.io/blog-site/post/cross_validation/"> Cross validation </a></li>
      
      <li><a href="http://gavinln.github.io/blog-site/post">Index</a> </li>
    </ul>

    <p>&copy; 2016. All rights reserved. </p>
  </div>
</div>


		<div class="content container">
			<div class="post">
			 	<h1>Decision trees on the Iris data set</h1>
			  <span class="post-date">Sun, Mar 13, 2016</span>
			      <p><a href="https://en.wikipedia.org/wiki/Decision_tree">Decision trees</a> are a non-parametric learning method used for <a href="https://en.wikipedia.org/wiki/Statistical_classification">classification</a> and <a href="https://en.wikipedia.org/wiki/Regression_analysis">regression</a>. Trees are often represented with a graph like model where each note is a test and each branch represents the outcome of the test.</p>

<p>We use the <a href="https://en.wikipedia.org/wiki/Iris_flower_data_set">Iris data set</a> to demonstrate the use of a decision tree classifier.</p>

<p>The Iris data set has four features (sepal length, sepal width, petal length, petal width) which can be used to classify Iris flowers into three species denoted as &ldquo;0&rdquo;, &ldquo;1&rdquo;, &ldquo;2&rdquo; (setosa, versicolor, virginica).</p>

<p>This Jupyter <a href="https://github.com/gavinln/stats_py_vm/blob/master/notebooks/scikit-learn/04_Decision_trees.ipynb">notebook</a> contains all the code used to plot the charts.</p>

<p>To better display the performance of the decision trees algorithm we predict
the species of Iris using just two features: petal length and petal width. The
species are shown in a scatter plot in different colors.</p>


<figure >
    
        <img src="http://gavinln.github.io/blog-site/img/irises/iris_species-petal_length-petal_width.png" width="600" />
    
    
    <figcaption>
        <h4>Scatter plot of Iris species</h4>
        
    </figcaption>
    
</figure>


<p>The output of the decision tree is shown using shaded regions that match the colors used to identify the flower. Using a decision tree with various depths the three species of Iris are classified, ineffectively at first with a tree of only one layer. As the number of layers increase the decision tree does a better job identifying the Iris species.</p>


<figure >
    
        <img src="http://gavinln.github.io/blog-site/img/decision_trees/decision_trees-multiple_depths.png" width="800" />
    
    
    <figcaption>
        <h4>Decision trees classification boundaries</h4>
        
    </figcaption>
    
</figure>


<p>The decision tree rules can also be represented using a graph like drawing with the root node on the left and the leaf nodes on the right.</p>

<p>
<figure >
    
        <img src="http://gavinln.github.io/blog-site/img/decision_trees/tree-depth-1.png" width="400" />
    
    
</figure>


<figure >
    
        <img src="http://gavinln.github.io/blog-site/img/decision_trees/tree-depth-2.png" width="600" />
    
    
</figure>


<figure >
    
        <img src="http://gavinln.github.io/blog-site/img/decision_trees/tree-depth-3.png" width="800" />
    
    
</figure>
</p>

<p>Finally we use a decision tree without limiting the depth. It classifies all the flowers correctly.</p>

<p>
<figure >
    
        <img src="http://gavinln.github.io/blog-site/img/decision_trees/decision_trees-unlimited_depth.png" width="600" />
    
    
</figure>
</p>

			</div>

			
		</div>

  </body>
</html>
